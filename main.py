import os
from flask import Flask, request, jsonify

import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

import faiss
import numpy as np
import json

app = Flask(__name__)

# ======================================================================
# âš¡ Vertex AI é…ç½®
# ======================================================================
PROJECT_ID = "colab-20250607"
LOCATION = "us-central1"
MODEL_NAME = "gemini-2.0-flash"
EMBED_MODEL = "text-embedding-005"

# é¢„åˆå§‹åŒ–æœåŠ¡è´¦å·
credentials = service_account.Credentials.from_service_account_file(
    "/secrets/vertex-json",
    scopes=["https://www.googleapis.com/auth/cloud-platform"],
)

vertexai.init(
    project=PROJECT_ID,
    location=LOCATION,
    credentials=credentials
)

embedder = GenerativeModel(EMBED_MODEL)
generator = GenerativeModel(MODEL_NAME)

# ======================================================================
# æ•°æ®è·¯å¾„
# ======================================================================
DOC_PATH = "knowledge.json"
EMBED_PATH = "embedding.npy"
INDEX_PATH = "faiss_index.index"

# ======================================================================
# åŠ è½½çŸ¥è¯†åº“
# ======================================================================
def load_knowledge():
    if not os.path.exists(DOC_PATH):
        print("â— knowledge.json ä¸å­˜åœ¨")
        return []
    with open(DOC_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

DOCUMENTS = load_knowledge()

# ======================================================================
# Vertex AI Embedding å‡½æ•°ï¼ˆæ›¿ä»£ HuggingFaceï¼‰
# ======================================================================
def embed_texts(text_list):
    """ä½¿ç”¨ Vertex AI text-embedding-005 ç”Ÿæˆå‘é‡"""
    responses = embedder.generate_content(text_list)
    # responses.embeddings æ˜¯ list[Embedding]
    vecs = np.array([e.values for e in responses.embeddings])
    return vecs

# ======================================================================
# æ„å»ºç´¢å¼•
# ======================================================================
def build_index(documents):
    print("âš¡ ç”Ÿæˆæ–‡æ¡£å‘é‡ï¼ˆVertex AI Embeddingï¼‰...")
    embeddings = embed_texts(documents)

    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))

    faiss.write_index(index, INDEX_PATH)
    np.save(EMBED_PATH, embeddings)

    print("âœ… å‘é‡ç´¢å¼•å·²ç”Ÿæˆ")
    return index


def load_index():
    if os.path.exists(INDEX_PATH) and os.path.exists(EMBED_PATH):
        print("ğŸ“¥ åŠ è½½å·²æœ‰ç´¢å¼•")
        return faiss.read_index(INDEX_PATH)
    else:
        print("âš  æ²¡æœ‰ç´¢å¼•ï¼Œæ­£åœ¨æ„å»º")
        return build_index(DOCUMENTS)

INDEX = load_index()

# ======================================================================
# Prompt æ¨¡æ¿
# ======================================================================
def build_prompt(context, query):
    return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Vertex AI åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ï¼š

ã€ç›¸å…³èµ„æ–™ã€‘
{context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

è¯·ç»™å‡ºå‡†ç¡®ã€æ¸…æ™°ã€åŸºäºèµ„æ–™çš„å›ç­”ï¼š
"""

# ======================================================================
# /generate ä¸»æ¥å£ï¼ˆCloud Run è°ƒç”¨ï¼‰
# ======================================================================
@app.route("/generate", methods=["POST"])
def generate():
    data = request.get_json()
    query = data.get("query", "").strip()

    if not query:
        return jsonify({"error": "ç¼ºå°‘ query å­—æ®µ"}), 400

    # ------------------------------------------------------------
    # 1ï¼‰å‘é‡å¬å›ï¼ˆRAGï¼‰
    # ------------------------------------------------------------
    query_vec = embed_texts([query])

    D, I = INDEX.search(np.array(query_vec), k=3)
    relevant_docs = [DOCUMENTS[i] for i in I[0] if i < len(DOCUMENTS)]

    context = "\n".join(relevant_docs)

    # ------------------------------------------------------------
    # 2ï¼‰æ„é€  Prompt
    # ------------------------------------------------------------
    prompt = build_prompt(context, query)

    # ------------------------------------------------------------
    # 3ï¼‰è°ƒç”¨ Gemini ç”Ÿæˆæœ€ç»ˆå›ç­”
    # ------------------------------------------------------------
    responses = generator.generate_content(prompt, stream=True)
    result = "".join([chunk.text for chunk in responses])

    return jsonify({"result": result})

# ======================================================================
# Cloud Run å¿…é¡»ç›‘å¬ PORT
# ======================================================================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    print(f"ğŸš€ Flask running on port {port}")
    app.run(host="0.0.0.0", port=port)
